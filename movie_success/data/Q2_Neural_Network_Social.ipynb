{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import statsmodels.api as sm\n",
    "from math import log10\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pandas.core import datetools\n",
    "import seaborn\n",
    "seaborn.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = pd.read_json('wiki-company.json.gz', orient='record', lines=True)\n",
    "rt = pd.read_json('rotten-tomatoes.json.gz', orient='record', lines=True)\n",
    "omdb = pd.read_json('omdb-data.json.gz', orient='record', lines=True)\n",
    "data_temp = wiki.merge(rt, on = 'rotten_tomatoes_id')\n",
    "data = data_temp.merge(omdb, left_on = 'imdb_id_x', right_on = 'imdb_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_to_number(x): \n",
    "    # transfer a dataframe column to number matrix\n",
    "    types =[]\n",
    "    type_size = 0\n",
    "    for i in range(len(x)):\n",
    "        for j in x[i]:\n",
    "            if j not in types:\n",
    "                types.append(j)\n",
    "                type_size = type_size + 1\n",
    "                \n",
    "    two_D_array = [x[:] for x in [[0] * len(types)] * len(x)] \n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        for j in x[i]:\n",
    "            index = 0\n",
    "            while j != types[index]:\n",
    "                index = index + 1\n",
    "            two_D_array[i][index] = 1        \n",
    "    \n",
    "    print('There are ', len(two_D_array[0]), ' different types in total.')\n",
    "    print('There are ', len(two_D_array), ' records collected.')\n",
    "    \n",
    "    return two_D_array\n",
    "\n",
    "def remove_rare_data(x,y,z):\n",
    "    # remove the elements in attribute 'y', which occurs fewer than 'z' times ,from dataframe 'x'\n",
    "    x_size = len(x[y])\n",
    "    types = []\n",
    "    times = []\n",
    "    x1 = []\n",
    "    y1 =[]\n",
    "    mark = [[] for i in range(len(x[y]))]\n",
    "    for i in range(x_size):\n",
    "        for j in range(len(x[y][i])):\n",
    "                if x[y][i][j] not in types:\n",
    "                    types.append(x[y][i][j])\n",
    "                    times.append(1)\n",
    "                    x1.append([i])\n",
    "                    y1.append([j])\n",
    "                else:\n",
    "                    index = types.index(x[y][i][j])\n",
    "                    times[index] = times[index] + 1 \n",
    "                    x1[index].append(i)\n",
    "                    y1[index].append(j)\n",
    "    for i in range(len(times)):\n",
    "        if times[i] <= z:\n",
    "            for j in range(times[i]):\n",
    "                mark[x1[i][j]].append(y1[i][j])\n",
    "    for i in range(x_size):\n",
    "        if len(mark[i]) != 0:\n",
    "            for j in sorted(mark[i], reverse=True):\n",
    "                del x[y][i][j] \n",
    "    for i in range(x_size):\n",
    "        if len(x[y][i]) == 0:\n",
    "            x = x.drop(i)\n",
    "    x = x.reset_index(drop = True)\n",
    "    print('Remove rare elements in ', y,  ' successfully')\n",
    "    return x\n",
    "\n",
    "def remove_rare_data_array(x, y):\n",
    "    measure = y\n",
    "    \n",
    "    # basically the same process as transfer_to_number() function\n",
    "    types =[]\n",
    "    type_size = 0\n",
    "    for i in range(len(x)):\n",
    "        for j in x[i]:\n",
    "            if j not in types:\n",
    "                types.append(j)\n",
    "                type_size = type_size + 1\n",
    "                \n",
    "    two_D_array = [x[:] for x in [[0] * len(types)] * len(x)] \n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        for j in x[i]:\n",
    "            index = 0\n",
    "            while j != types[index]:\n",
    "                index = index + 1\n",
    "            two_D_array[i][index] = 1    \n",
    "\n",
    "    sum = [0]* len(two_D_array[0])\n",
    "    # print(sum)\n",
    "    for i in range(len(two_D_array)):\n",
    "        for j in range(len(two_D_array[0])):   \n",
    "            if two_D_array[i][j] == 1:\n",
    "                # if there is a score (record) on this genre, mark it\n",
    "                sum[j] = sum[j] + 1\n",
    "    \n",
    "    x_more_than_y_times = len(types)\n",
    "    \n",
    "    # if that element (e.g. director) appears only once, we set the whole column to be -1 \n",
    "    for i in range(len(sum)):\n",
    "        if sum[i] <= measure:\n",
    "            x_more_than_y_times = x_more_than_y_times - 1\n",
    "            for j in range(len(two_D_array)):\n",
    "                two_D_array[j][i] = -1\n",
    "    \n",
    "    # delete the whole -1 column\n",
    "    for i in range(len(two_D_array)):\n",
    "        two_D_array[i] = [e for e in two_D_array[i] if e not in (-2, -1)]\n",
    "    \n",
    "    # remove movies with all 0's in a row. (No director)\n",
    "    two_D_array = [v for v in two_D_array if sum(v) != 0]\n",
    "    return two_D_array\n",
    "\n",
    "def extract_first_2(x):\n",
    "    if len(x) <= 2:\n",
    "        return x\n",
    "    else:\n",
    "        return x[:2]\n",
    "    \n",
    "def extract_first_3(x):\n",
    "    if len(x) <= 3:\n",
    "        return x\n",
    "    else:\n",
    "        return x[:3]\n",
    "\n",
    "def extract_first_4(x):\n",
    "    if len(x) <= 4:\n",
    "        return x\n",
    "    else:\n",
    "        return x[:4]\n",
    "\n",
    "def to_list(x):\n",
    "    return [x]\n",
    "\n",
    "def combine_list(x,y):\n",
    "    #combine two 2d lists together\n",
    "    for i in range(len(x)):\n",
    "        x[i].extend(y[i])\n",
    "    return x\n",
    "\n",
    "def model_test(model,X_test,y_test,a):\n",
    "    # Using model \"model\" and input data \"X_test\", \"y_test\"\n",
    "    accept = 0\n",
    "    real = np.asarray(y_test, dtype=\"float64\")\n",
    "    predict = np.asarray(model.predict(X_test), dtype=\"float64\")\n",
    "    difference = np.absolute(real - predict)\n",
    "    for i in range(real.size):\n",
    "        if difference[i] <= a:\n",
    "            accept = accept + 1\n",
    "    score = accept/real.size\n",
    "    print ('The corrected score for testing data is: ', score)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "public = data[['director','cast_member','genre','production_company','audience_average','critic_average', 'audience_ratings']]\n",
    "public = public.dropna(subset = ['director','cast_member','genre','production_company','audience_average','critic_average', 'audience_ratings'])\n",
    "public = public[public['audience_ratings']>=40].reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2867"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(public)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "public['director'] = public['director'].apply(extract_first_2)\n",
    "public['cast_member'] = public['cast_member'].apply(extract_first_4)\n",
    "public['genre'] = public['genre'].apply(extract_first_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove rare elements in  cast_member  successfully\n",
      "Remove rare elements in  director  successfully\n"
     ]
    }
   ],
   "source": [
    "public = remove_rare_data(public, 'cast_member', 1)\n",
    "public = remove_rare_data(public, 'director', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  500  different types in total.\n",
      "There are  2867  records collected.\n",
      "There are  770  different types in total.\n",
      "There are  2867  records collected.\n",
      "There are  2387  different types in total.\n",
      "There are  2867  records collected.\n",
      "There are  161  different types in total.\n",
      "There are  2867  records collected.\n"
     ]
    }
   ],
   "source": [
    "public['production_company'] = public['production_company'].apply(to_list)\n",
    "\n",
    "company = transfer_to_number(public['production_company'])\n",
    "director = transfer_to_number(public['director'])\n",
    "cast_member= transfer_to_number(public['cast_member'])\n",
    "genre = transfer_to_number(public['genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combine_list(director,cast_member)\n",
    "X = combine_list(X, genre)\n",
    "X = combine_list(X, company)\n",
    "y_1 = np.asarray(public['audience_average'], dtype=\"|S6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The corrected score for testing data is:  0.2928870292887029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9990697674418605"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X, y_1)\n",
    "model = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(20))\n",
    "model.fit(X_train_1, y_train_1)\n",
    "model.predict(X_test_1)\n",
    "model_test(model, X_test_1,y_test_1,0.15)\n",
    "model.score(X_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The corrected score for testing data is:  0.05718270571827057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9455813953488372"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_2 = np.asarray(public['critic_average'], dtype=\"|S6\")\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X, y_2)\n",
    "model1 = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(5))\n",
    "model1.fit(X_train_2, y_train_2)\n",
    "model1.predict(X_test_2)\n",
    "model_test(model1, X_test_2,y_test_2,0.2)\n",
    "model1.score(X_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The corrected score for testing data is:  0.07670850767085077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9995348837209302"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X = combine_list(director, cast_member)\n",
    "new_X = combine_list(new_X, genre)\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(new_X, y_2)\n",
    "model2 = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(10))\n",
    "model2.fit(X_train_3, y_train_3)\n",
    "model2.predict(X_test_3)\n",
    "model_test(model2, X_test_3,y_test_3,0.2)\n",
    "model2.score(X_train_3, y_train_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_forest = RandomForestClassifier(n_estimators = 200, max_depth = 10, min_samples_leaf = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The corrected score for testing data is:  0.43235704323570434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.14604651162790697"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_forest.fit(X_train_1, y_train_1)\n",
    "model_test(model_forest, X_test_1,y_test_1,0.25)\n",
    "model_forest.score(X_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The corrected score for testing data is:  0.13807531380753138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10093023255813953"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_forest.fit(X_train_3, y_train_3)\n",
    "model_test(model_forest, X_test_3,y_test_3,0.25)\n",
    "model_forest.score(X_train_3, y_train_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The corrected score for testing data is:  0.3333333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.29255813953488374"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wow wow wow this is so good.\n",
    "model_tree = DecisionTreeClassifier(max_depth=50)\n",
    "model_tree.fit(X_train_1, y_train_1)\n",
    "model_test(model_tree, X_test_1,y_test_1,0.2)\n",
    "model_tree.score(X_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
