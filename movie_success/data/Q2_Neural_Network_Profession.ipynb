{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwa117/sfuhome/cmpt-353/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import statsmodels.api as sm\n",
    "from math import log10\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from pandas.core import datetools\n",
    "import seaborn\n",
    "seaborn.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = pd.read_json('wiki-company.json.gz', orient='record', lines=True)\n",
    "rt = pd.read_json('rotten-tomatoes.json.gz', orient='record', lines=True)\n",
    "omdb = pd.read_json('omdb-data.json.gz', orient='record', lines=True)\n",
    "data_temp = wiki.merge(rt, on = 'rotten_tomatoes_id')\n",
    "data = data_temp.merge(omdb, left_on = 'imdb_id_x', right_on = 'imdb_id')\n",
    "# data = data.dropna(subset = ['nbox', 'ncost', 'publication_date', 'cast_member','director' ,'production_company', 'audience_average', 'audience_percent','critic_average', 'critic_percent'])\n",
    "# data.info()\n",
    "# Have a look on each attribute in this dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin the filtering:\n",
    "def corr_points(x):\n",
    "    oscar_win = re.search(r'Won (\\d+) Oscar', x)\n",
    "    oscar_nominated = re.search(r'Nominated for (\\d+) Oscar', x)\n",
    "    GoldenG_win = re.search(r'Won (\\d+) Golden', x)\n",
    "    GoldenG_nominated = re.search(r'Nominated for (\\d+) Golden', x)\n",
    "    minor_wins = re.search(r'(\\d+) win', x)\n",
    "    minor_nominations = re.search(r'(\\d+) nomination', x)\n",
    "    score = 0\n",
    "    if oscar_win:\n",
    "        score = score + 10 * int(oscar_win.group(1))\n",
    "    if oscar_nominated:\n",
    "        score = score + 5 * int(oscar_nominated.group(1))\n",
    "    if GoldenG_win:\n",
    "        score = score + 7 * int(GoldenG_win.group(1))\n",
    "    if GoldenG_nominated:\n",
    "        score = score + 3 * int(GoldenG_nominated.group(1))\n",
    "    if minor_wins:\n",
    "        score = score + int(minor_wins.group(1))\n",
    "    if minor_nominations:\n",
    "        score = score + 0.25 * int(minor_nominations.group(1))\n",
    "    return score\n",
    "\n",
    "# weighted points is associated with a movie's PROFESSIONAL SUCCESS\n",
    "# this point is based on weights among oscar, golden globe and other wins / nominations\n",
    "data['weighted_points'] = data['omdb_awards'].map(corr_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the information that we really need, and drop N/A values\n",
    "professional = data[['director','cast_member','genre','production_company','weighted_points']]\n",
    "professional = professional.dropna(subset = ['director','cast_member','genre','production_company','weighted_points']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only focus on main values, such as main directors, protagonists and major genres\n",
    "def extract_first_2(x):\n",
    "    if len(x) <= 2:\n",
    "        return x\n",
    "    else:\n",
    "        return x[:2]\n",
    "    \n",
    "def extract_first_3(x):\n",
    "    if len(x) <= 3:\n",
    "        return x\n",
    "    else:\n",
    "        return x[:3]\n",
    "\n",
    "def extract_first_4(x):\n",
    "    if len(x) <= 4:\n",
    "        return x\n",
    "    else:\n",
    "        return x[:4]\n",
    "    \n",
    "professional['director'] = professional['director'].apply(extract_first_2)\n",
    "professional['cast_member'] = professional['cast_member'].apply(extract_first_4)\n",
    "professional['genre'] = professional['genre'].apply(extract_first_3)\n",
    "# Filtering down.Could have a look:\n",
    "# print(professional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3355"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(professional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove rare elements in  cast_member  successfully\n",
      "Remove rare elements in  director  successfully\n"
     ]
    }
   ],
   "source": [
    "def transfer_to_number(x): \n",
    "    # transfer a dataframe column to number matrix\n",
    "    types =[]\n",
    "    type_size = 0\n",
    "    for i in range(len(x)):\n",
    "        for j in x[i]:\n",
    "            if j not in types:\n",
    "                types.append(j)\n",
    "                type_size = type_size + 1\n",
    "                \n",
    "    two_D_array = [x[:] for x in [[0] * len(types)] * len(x)] \n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        for j in x[i]:\n",
    "            index = 0\n",
    "            while j != types[index]:\n",
    "                index = index + 1\n",
    "            two_D_array[i][index] = 1        \n",
    "    \n",
    "    print('There are ', len(two_D_array[0]), ' different types in total.')\n",
    "    print('There are ', len(two_D_array), ' records collected.')\n",
    "    \n",
    "    return two_D_array\n",
    "\n",
    "def remove_rare_data(x,y,z):\n",
    "    # remove the elements in attribute 'y', which occurs fewer than 'z' times ,from dataframe 'x'\n",
    "    x_size = len(x[y])\n",
    "    types = []\n",
    "    times = []\n",
    "    x1 = []\n",
    "    y1 =[]\n",
    "    mark = [[] for i in range(len(x[y]))]\n",
    "    for i in range(x_size):\n",
    "        for j in range(len(x[y][i])):\n",
    "                if x[y][i][j] not in types:\n",
    "                    types.append(x[y][i][j])\n",
    "                    times.append(1)\n",
    "                    x1.append([i])\n",
    "                    y1.append([j])\n",
    "                else:\n",
    "                    index = types.index(x[y][i][j])\n",
    "                    times[index] = times[index] + 1 \n",
    "                    x1[index].append(i)\n",
    "                    y1[index].append(j)\n",
    "    for i in range(len(times)):\n",
    "        if times[i] <= z:\n",
    "            for j in range(times[i]):\n",
    "                mark[x1[i][j]].append(y1[i][j])\n",
    "    for i in range(x_size):\n",
    "        if len(mark[i]) != 0:\n",
    "            for j in sorted(mark[i], reverse=True):\n",
    "                del x[y][i][j] \n",
    "    for i in range(x_size):\n",
    "        if len(x[y][i]) == 0:\n",
    "            x = x.drop(i)\n",
    "    x = x.reset_index(drop = True)\n",
    "    print('Remove rare elements in ', y,  ' successfully')\n",
    "    return x\n",
    "\n",
    "def remove_rare_data_array(x, y):\n",
    "    measure = y\n",
    "    \n",
    "    # basically the same process as transfer_to_number() function\n",
    "    types =[]\n",
    "    type_size = 0\n",
    "    for i in range(len(x)):\n",
    "        for j in x[i]:\n",
    "            if j not in types:\n",
    "                types.append(j)\n",
    "                type_size = type_size + 1\n",
    "                \n",
    "    two_D_array = [x[:] for x in [[0] * len(types)] * len(x)] \n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        for j in x[i]:\n",
    "            index = 0\n",
    "            while j != types[index]:\n",
    "                index = index + 1\n",
    "            two_D_array[i][index] = 1    \n",
    "\n",
    "    sum = [0]* len(two_D_array[0])\n",
    "    # print(sum)\n",
    "    for i in range(len(two_D_array)):\n",
    "        for j in range(len(two_D_array[0])):   \n",
    "            if two_D_array[i][j] == 1:\n",
    "                # if there is a score (record) on this genre, mark it\n",
    "                sum[j] = sum[j] + 1\n",
    "    \n",
    "    x_more_than_y_times = len(types)\n",
    "    \n",
    "    # if that element (e.g. director) appears only once, we set the whole column to be -1 \n",
    "    for i in range(len(sum)):\n",
    "        if sum[i] <= measure:\n",
    "            x_more_than_y_times = x_more_than_y_times - 1\n",
    "            for j in range(len(two_D_array)):\n",
    "                two_D_array[j][i] = -1\n",
    "    \n",
    "    # delete the whole -1 column\n",
    "    for i in range(len(two_D_array)):\n",
    "        two_D_array[i] = [e for e in two_D_array[i] if e not in (-2, -1)]\n",
    "    \n",
    "    # remove movies with all 0's in a row. (No director)\n",
    "    two_D_array = [v for v in two_D_array if sum(v) != 0]\n",
    "    return two_D_array\n",
    "\n",
    "professional = remove_rare_data(professional, 'cast_member', 1)\n",
    "professional = remove_rare_data(professional, 'director', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  575  different types in total.\n",
      "There are  3355  records collected.\n",
      "There are  905  different types in total.\n",
      "There are  3355  records collected.\n",
      "There are  2812  different types in total.\n",
      "There are  3355  records collected.\n",
      "There are  174  different types in total.\n",
      "There are  3355  records collected.\n"
     ]
    }
   ],
   "source": [
    "def to_list(x):\n",
    "    return [x]\n",
    "professional['production_company'] = professional['production_company'].apply(to_list)\n",
    "\n",
    "company = transfer_to_number(professional['production_company'])\n",
    "director = transfer_to_number(professional['director'])\n",
    "cast_member= transfer_to_number(professional['cast_member'])\n",
    "genre = transfer_to_number(professional['genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_list(x,y):\n",
    "    #combine two 2d lists together\n",
    "    for i in range(len(x)):\n",
    "        x[i].extend(y[i])\n",
    "    return x\n",
    "\n",
    "def model_test(model,X_test,y_test,a):\n",
    "    # Using model \"model\" and input data \"X_test\", \"y_test\"\n",
    "    accept = 0\n",
    "    real = np.asarray(y_test, dtype=\"float64\")\n",
    "    predict = np.asarray(model.predict(X_test), dtype=\"float64\")\n",
    "    difference = np.absolute(real - predict)\n",
    "    for i in range(real.size):\n",
    "        if difference[i] <= a:\n",
    "            accept = accept + 1\n",
    "    score = accept/real.size\n",
    "    print ('The test score is: ', score)\n",
    "    return 0\n",
    "\n",
    "X = combine_list(director,cast_member)\n",
    "X = combine_list(X, genre)\n",
    "X = combine_list(X, company)\n",
    "y = np.asarray(professional['weighted_points'], dtype=\"|S6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test score is:  0.6471990464839095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.42090620031796505"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# User Neural Network to test\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X, y)\n",
    "model = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(25,15,5))\n",
    "model.fit(X_train_2, y_train_2)\n",
    "model.predict(X_test_2)\n",
    "model_test(model, X_test_2,y_test_2,5)\n",
    "model.score(X_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
